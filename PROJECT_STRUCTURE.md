# Project Structure

## ğŸ“ Directory Layout

```
RAG_chatBot/
â”œâ”€â”€ backend/                    # Python FastAPI backend
â”‚   â”œâ”€â”€ main.py                # FastAPI application entry point
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ Procfile              # Railway deployment config
â”‚   â”œâ”€â”€ railway.json          # Railway configuration
â”‚   â”œâ”€â”€ env.example           # Environment variables template
â”‚   â”œâ”€â”€ .gitignore            # Git ignore rules
â”‚   â””â”€â”€ services/             # Service modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ pdf_extractor.py  # PDF text extraction using PyMuPDF
â”‚       â”œâ”€â”€ url_scraper.py    # URL content scraping
â”‚       â”œâ”€â”€ vector_store.py   # ChromaDB vector database operations
â”‚       â””â”€â”€ rag_service.py    # RAG pipeline & LLM integration
â”‚
â”œâ”€â”€ frontend/                  # Next.js frontend
â”‚   â”œâ”€â”€ app/                  # Next.js 14 app directory
â”‚   â”‚   â”œâ”€â”€ page.tsx          # Main chat interface component
â”‚   â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â”‚   â””â”€â”€ globals.css       # Global styles
â”‚   â”œâ”€â”€ package.json          # Node.js dependencies
â”‚   â”œâ”€â”€ tsconfig.json         # TypeScript configuration
â”‚   â”œâ”€â”€ tailwind.config.js    # Tailwind CSS configuration
â”‚   â”œâ”€â”€ next.config.js        # Next.js configuration
â”‚   â””â”€â”€ postcss.config.js     # PostCSS configuration
â”‚
â”œâ”€â”€ README.md                  # Main documentation
â”œâ”€â”€ QUICKSTART.md             # Quick start guide
â””â”€â”€ .gitignore                # Root git ignore

```

## ğŸ”§ Key Components

### Backend Services

1. **PDF Extractor** (`services/pdf_extractor.py`)
   - Uses PyMuPDF (fitz) to extract text from PDF files
   - Handles multi-page documents

2. **URL Scraper** (`services/url_scraper.py`)
   - Uses Newspaper3k for article extraction
   - Falls back to BeautifulSoup for general web scraping
   - Handles various website structures

3. **Vector Store** (`services/vector_store.py`)
   - Manages ChromaDB persistent storage
   - Uses SentenceTransformers for embeddings (all-MiniLM-L6-v2)
   - Handles text chunking with overlap
   - Provides search functionality

4. **RAG Service** (`services/rag_service.py`)
   - Implements RAG pipeline
   - Retrieves relevant context from vector store
   - Integrates with Groq API or Hugging Face Inference API
   - Formats responses with source citations

### Frontend Components

1. **Main Page** (`app/page.tsx`)
   - Chat interface with message history
   - PDF upload functionality
   - URL input and scraping
   - Document list with delete functionality
   - Real-time chat with loading states

## ğŸ”Œ API Endpoints

- `GET /` - API status
- `GET /health` - Health check
- `POST /api/upload-pdf` - Upload and process PDF
- `POST /api/scrape-url` - Scrape URL content
- `POST /api/chat` - Chat with RAG
- `GET /api/documents` - List all documents
- `DELETE /api/documents/{doc_id}` - Delete a document

## ğŸ—„ï¸ Data Flow

1. **Upload/Scrape** â†’ Extract text â†’ Chunk text â†’ Generate embeddings â†’ Store in ChromaDB
2. **Query** â†’ Generate query embedding â†’ Search ChromaDB â†’ Retrieve top chunks â†’ Format context â†’ Send to LLM â†’ Return answer with sources

## ğŸ” Environment Variables

### Backend (.env)
- `GROQ_API_KEY` - Groq API key for LLM
- `HUGGINGFACE_API_KEY` - Hugging Face API key (alternative)
- `USE_GROQ` - Boolean to choose LLM provider
- `CHROMA_DB_PATH` - Path to ChromaDB storage

### Frontend (.env.local)
- `NEXT_PUBLIC_API_URL` - Backend API URL

